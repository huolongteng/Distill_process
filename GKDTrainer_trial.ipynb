{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install needed package."
      ],
      "metadata": {
        "id": "_AQaS1bE6Moq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install trl"
      ],
      "metadata": {
        "id": "xHGxJ9VnApo-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and basic setups."
      ],
      "metadata": {
        "id": "M6yRSVtm6Sqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding,\n",
        "    set_seed,\n",
        ")\n",
        "from trl.experimental.gkd import GKDConfig, GKDTrainer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sN1F-xu-6KWa",
        "outputId": "108f9157-b558-4e0f-936f-7e8c9d25be65"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2201172770.py:13: TRLExperimentalWarning: You are importing from 'trl.experimental'. APIs here are unstable and may change or be removed without notice. Silence this warning by setting environment variable TRL_EXPERIMENTAL_SILENCE=1.\n",
            "  from trl.experimental.gkd import GKDConfig, GKDTrainer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config."
      ],
      "metadata": {
        "id": "sjI4ab6z6Y87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 57382\n",
        "set_seed(SEED)\n",
        "\n",
        "STUDENT_CKPT = \"Qwen/Qwen2-0.5B-Instruct\"\n",
        "TEACHER_CKPT = \"Qwen/Qwen2-1.5B-Instruct\"\n",
        "\n",
        "# Small subset for a full end-to-end smoke test\n",
        "TRAIN_N = 200\n",
        "EVAL_N = 50\n",
        "\n",
        "MAX_LENGTH = 512\n",
        "\n",
        "OUTDIR_BASELINE = \"./baseline_ce_eval\"\n",
        "OUTDIR_GKD = \"./gkd-model\"\n",
        "OUTDIR_DISTILLED = \"./distilled_ce_eval\""
      ],
      "metadata": {
        "id": "I8PqDXsK6bmx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load models and ..\n"
      ],
      "metadata": {
        "id": "YKAiI0SP6gtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(STUDENT_CKPT)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "student_model = AutoModelForCausalLM.from_pretrained(\n",
        "    STUDENT_CKPT,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "teacher_model = AutoModelForCausalLM.from_pretrained(\n",
        "    TEACHER_CKPT,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# Make teacher frozen & eval (saves memory + avoids accidental grads)\n",
        "teacher_model.eval()\n",
        "for p in teacher_model.parameters():\n",
        "    p.requires_grad_(False)\n",
        "\n",
        "# Disable KV cache during training/eval to reduce memory spikes\n",
        "student_model.config.use_cache = False\n",
        "teacher_model.config.use_cache = False\n",
        "\n",
        "\n",
        "def _model_vocab_size(m):\n",
        "    emb = m.get_input_embeddings()\n",
        "    return None if emb is None else int(emb.num_embeddings)\n",
        "\n",
        "\n",
        "# If vocab mismatch happens (rare for same-family models), fall back to teacher tokenizer for teacher CE eval.\n",
        "# This keeps the CE definition the same, but tokenization may differ slightly.\n",
        "teacher_tokenizer = tokenizer\n",
        "if _model_vocab_size(teacher_model) is not None and _model_vocab_size(teacher_model) != len(tokenizer):\n",
        "    teacher_tokenizer = AutoTokenizer.from_pretrained(TEACHER_CKPT)\n",
        "    if teacher_tokenizer.pad_token is None:\n",
        "        teacher_tokenizer.pad_token = teacher_tokenizer.eos_token\n",
        "    teacher_tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssaB-1DQ6f_d",
        "outputId": "44be5027-91f8-432f-cb22-c8ced483f2c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup dataset."
      ],
      "metadata": {
        "id": "20aApuv66r4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")\n",
        "\n",
        "# Make a train/eval split (dataset itself is a single split)\n",
        "split = raw.train_test_split(test_size=0.02, seed=SEED)\n",
        "train_raw = split[\"train\"].shuffle(seed=SEED).select(range(min(TRAIN_N, len(split[\"train\"]))))\n",
        "eval_raw = split[\"test\"].shuffle(seed=SEED).select(range(min(EVAL_N, len(split[\"test\"]))))\n",
        "\n",
        "\n",
        "def dolly_to_messages(ex):\n",
        "    \"\"\"\n",
        "    Convert Dolly record to ChatML-like messages:\n",
        "      user: instruction (+ optional context)\n",
        "      assistant: response\n",
        "    \"\"\"\n",
        "    instruction = (ex.get(\"instruction\") or \"\").strip()\n",
        "    context = (ex.get(\"context\") or \"\").strip()\n",
        "    response = (ex.get(\"response\") or \"\").strip()\n",
        "\n",
        "    if context:\n",
        "        user = f\"Instruction:\\n{instruction}\\n\\nContext:\\n{context}\"\n",
        "    else:\n",
        "        user = f\"Instruction:\\n{instruction}\"\n",
        "\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": user},\n",
        "            {\"role\": \"assistant\", \"content\": response},\n",
        "        ]\n",
        "    }\n",
        "\n",
        "\n",
        "train_dataset = train_raw.map(dolly_to_messages, remove_columns=train_raw.column_names)\n",
        "eval_dataset = eval_raw.map(dolly_to_messages, remove_columns=eval_raw.column_names)"
      ],
      "metadata": {
        "id": "gdBUghqN6rDc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_for_ce_eval(example, tok, max_length=512):\n",
        "    \"\"\"\n",
        "    Build labels so that ONLY assistant response tokens contribute to CE loss.\n",
        "    Prompt tokens (user + assistant header) are masked with -100.\n",
        "    \"\"\"\n",
        "    messages = example[\"messages\"]\n",
        "\n",
        "    full_text = tok.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=False,\n",
        "    )\n",
        "    prompt_text = tok.apply_chat_template(\n",
        "        messages[:-1],\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True,  # ends right before assistant content\n",
        "    )\n",
        "\n",
        "    full = tok(\n",
        "        full_text,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        padding=False,\n",
        "        add_special_tokens=True,\n",
        "    )\n",
        "    prompt = tok(\n",
        "        prompt_text,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        padding=False,\n",
        "        add_special_tokens=True,\n",
        "    )\n",
        "\n",
        "    input_ids = full[\"input_ids\"]\n",
        "    attention_mask = full[\"attention_mask\"]\n",
        "\n",
        "    prompt_len = min(len(prompt[\"input_ids\"]), len(input_ids))\n",
        "    labels = [-100] * prompt_len + input_ids[prompt_len:]\n",
        "\n",
        "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n",
        "\n",
        "\n",
        "class DataCollatorForCausalLMEval:\n",
        "    \"\"\"Pads input_ids/attention_mask with tokenizer; pads labels with -100.\"\"\"\n",
        "    def __init__(self, tok):\n",
        "        self.tok = tok\n",
        "        self.padder = DataCollatorWithPadding(tokenizer=tok, padding=True)\n",
        "\n",
        "    def __call__(self, features):\n",
        "        labels = [f[\"labels\"] for f in features]\n",
        "        feats = [{k: v for k, v in f.items() if k != \"labels\"} for f in features]\n",
        "        batch = self.padder(feats)\n",
        "\n",
        "        max_len = batch[\"input_ids\"].shape[1]\n",
        "        padded_labels = []\n",
        "        for lab in labels:\n",
        "            padded_labels.append(lab + [-100] * (max_len - len(lab)))\n",
        "\n",
        "        batch[\"labels\"] = torch.tensor(padded_labels, dtype=torch.long)\n",
        "        return batch\n",
        "\n",
        "\n",
        "def build_tokenized_eval(ds, tok, max_length=512):\n",
        "    return ds.map(\n",
        "        lambda ex: tokenize_for_ce_eval(ex, tok, max_length=max_length),\n",
        "        remove_columns=ds.column_names,\n",
        "    )\n",
        "\n",
        "\n",
        "def evaluate_ce_loss(model, tok, tokenized_eval_ds, out_dir, batch_size=4):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      metrics dict with eval_loss, plus ppl (exp(loss)) for convenience.\n",
        "    \"\"\"\n",
        "    args = TrainingArguments(\n",
        "        output_dir=out_dir,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        do_train=False,\n",
        "        do_eval=True,\n",
        "        report_to=\"none\",\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        eval_dataset=tokenized_eval_ds,\n",
        "        tokenizer=tok,\n",
        "        data_collator=DataCollatorForCausalLMEval(tok),\n",
        "    )\n",
        "\n",
        "    metrics = trainer.evaluate()\n",
        "    loss = float(metrics[\"eval_loss\"])\n",
        "    ppl = math.exp(loss) if loss < 20 else float(\"inf\")\n",
        "    metrics[\"eval_ppl\"] = ppl\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# Pre-tokenize eval once (for student)\n",
        "tokenized_eval_student = build_tokenized_eval(eval_dataset, tokenizer, max_length=MAX_LENGTH)\n",
        "\n",
        "# Teacher may need its own tokenized eval if tokenizer fallback happened\n",
        "tokenized_eval_teacher = tokenized_eval_student\n",
        "if teacher_tokenizer is not tokenizer:\n",
        "    tokenized_eval_teacher = build_tokenized_eval(eval_dataset, teacher_tokenizer, max_length=MAX_LENGTH)"
      ],
      "metadata": {
        "id": "JVxoayRV6yOU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline evaluation."
      ],
      "metadata": {
        "id": "i2f78Jha67Yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Baseline CE evaluation (answer-only, unified definition) ===\")\n",
        "\n",
        "teacher_metrics = evaluate_ce_loss(\n",
        "    model=teacher_model,\n",
        "    tok=teacher_tokenizer,\n",
        "    tokenized_eval_ds=tokenized_eval_teacher,\n",
        "    out_dir=f\"{OUTDIR_BASELINE}/teacher\",\n",
        "    batch_size=4,\n",
        ")\n",
        "print(f\"[Teacher] ce_eval_loss={teacher_metrics['eval_loss']:.4f} | ppl={teacher_metrics['eval_ppl']:.2f}\")\n",
        "\n",
        "student_metrics = evaluate_ce_loss(\n",
        "    model=student_model,\n",
        "    tok=tokenizer,\n",
        "    tokenized_eval_ds=tokenized_eval_student,\n",
        "    out_dir=f\"{OUTDIR_BASELINE}/student\",\n",
        "    batch_size=4,\n",
        ")\n",
        "print(f\"[Student] ce_eval_loss={student_metrics['eval_loss']:.4f} | ppl={student_metrics['eval_ppl']:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "FtGKVj4M65_8",
        "outputId": "fd74a603-fdae-4d38-a224-2491d70cd6f4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1481963763.py:83: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Baseline CE evaluation (answer-only, unified definition) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13/13 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1481963763.py:83: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Teacher] ce_eval_loss=1.6615 | ppl=5.27\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13/13 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Student] ce_eval_loss=1.8408 | ppl=6.30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run distillation with GKD."
      ],
      "metadata": {
        "id": "jp9huDRs7RfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Start GKD distillation (training logs show GKD loss; CE is evaluated separately) ===\")\n",
        "\n",
        "gkd_args = GKDConfig(\n",
        "    output_dir=OUTDIR_GKD,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=8,\n",
        "    num_train_epochs=3\n",
        ")\n",
        "\n",
        "gkd_trainer = GKDTrainer(\n",
        "    model=student_model,\n",
        "    teacher_model=teacher_model,\n",
        "    args=gkd_args,\n",
        "    processing_class=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,  # kept so Trainer can run its own eval if you enable it later\n",
        ")\n",
        "\n",
        "gkd_trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "haf6hMHU7BU0",
        "outputId": "d28c746d-a860-4035-de26-5bd4db838700"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Start GKD distillation (training logs show GKD loss; CE is evaluated separately) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgreatgoose\u001b[0m (\u001b[33mgreatgoose-none\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251222_074013-2ru9ptfi</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/greatgoose-none/huggingface/runs/2ru9ptfi' target=\"_blank\">swift-cloud-9</a></strong> to <a href='https://wandb.ai/greatgoose-none/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/greatgoose-none/huggingface' target=\"_blank\">https://wandb.ai/greatgoose-none/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/greatgoose-none/huggingface/runs/2ru9ptfi' target=\"_blank\">https://wandb.ai/greatgoose-none/huggingface/runs/2ru9ptfi</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`generation_config` default values have been modified to match model-specific defaults: {'top_p': 0.8, 'repetition_penalty': 1.1}. If this is not desired, please set these values explicitly.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [75/75 15:34, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.616000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.643800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.675700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.534600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.535700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.466700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.527700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=75, training_loss=0.5681931972503662, metrics={'train_runtime': 950.3154, 'train_samples_per_second': 0.631, 'train_steps_per_second': 0.079, 'total_flos': 234086839134720.0, 'train_loss': 0.5681931972503662, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Post-distillation CE evaluation (answer-only, same metric as baseline) ===\")\n",
        "\n",
        "distilled_metrics = evaluate_ce_loss(\n",
        "    model=student_model,  # updated by distillation\n",
        "    tok=tokenizer,\n",
        "    tokenized_eval_ds=tokenized_eval_student,  # same eval set, same tokenization\n",
        "    out_dir=OUTDIR_DISTILLED,\n",
        "    batch_size=4,\n",
        ")\n",
        "print(f\"[Distilled Student] ce_eval_loss={distilled_metrics['eval_loss']:.4f} | ppl={distilled_metrics['eval_ppl']:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "ZU3rDU2q7YtO",
        "outputId": "fe6ddde1-e70b-46b1-fa8c-79d8cc6318c4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1481963763.py:83: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Post-distillation CE evaluation (answer-only, same metric as baseline) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13/13 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Distilled Student] ce_eval_loss=1.8608 | ppl=6.43\n"
          ]
        }
      ]
    }
  ]
}